@article{10.1093/gigascience/giz044,
  author          = {Lampa, Samuel and Dahlö, Martin and Alvarsson, Jonathan and
                  Spjuth, Ola},
  title           = "{SciPipe: A workflow library for agile development of
                  complex and dynamic bioinformatics pipelines}",
  journal         = {GigaScience},
  volume          = 8,
  number          = 5,
  year            = 2019,
  month           = 04,
  abstract        = "{The complex nature of biological data has driven the
                  development of specialized software tools. Scientific workflow
                  management systems simplify the assembly of such tools into
                  pipelines, assist with job automation, and aid reproducibility
                  of analyses. Many contemporary workflow tools are specialized
                  or not designed for highly complex workflows, such as with
                  nested loops, dynamic scheduling, and parametrization, which
                  is common in, e.g., machine learning.SciPipe is a workflow
                  programming library implemented in the programming language
                  Go, for managing complex and dynamic pipelines in
                  bioinformatics, cheminformatics, and other fields. SciPipe
                  helps in particular with workflow constructs common in machine
                  learning, such as extensive branching, parameter sweeps, and
                  dynamic scheduling and parametrization of downstream tasks.
                  SciPipe builds on flow-based programming principles to support
                  agile development of workflows based on a library of
                  self-contained, reusable components. It supports running
                  subsets of workflows for improved iterative development and
                  provides a data-centric audit logging feature that saves a
                  full audit trace for every output file of a workflow, which
                  can be converted to other formats such as HTML, TeX, and PDF
                  on demand. The utility of SciPipe is demonstrated with a
                  machine learning pipeline, a genomics, and a transcriptomics
                  pipeline.SciPipe provides a solution for agile development of
                  complex and dynamic pipelines, especially in machine learning,
                  through a flexible application programming interface suitable
                  for scientists used to programming or scripting.}",
  issn            = {2047-217X},
  doi             = {10.1093/gigascience/giz044},
  url             = {https://doi.org/10.1093/gigascience/giz044},
  note            = {giz044},
  eprint          =
                  {https://academic.oup.com/gigascience/article-pdf/8/5/giz044/28538390/giz044\_reviewer\_3\_report\_original\_submission.pdf},
}

@article{10.1145/1013208.1013209,
  author          = {Johnston, Wesley M. and Hanna, J. R. Paul and Millar,
                  Richard J.},
  title           = {Advances in Dataflow Programming Languages},
  year            = 2004,
  issue_date      = {March 2004},
  publisher       = {Association for Computing Machinery},
  address         = {New York, NY, USA},
  volume          = 36,
  number          = 1,
  issn            = {0360-0300},
  url             = {https://doi.org/10.1145/1013208.1013209},
  doi             = {10.1145/1013208.1013209},
  abstract        = {Many developments have taken place within dataflow
                  programming languages in the past decade. In particular, there
                  has been a great deal of activity and advancement in the field
                  of dataflow visual programming languages. The motivation for
                  this article is to review the content of these recent
                  developments and how they came about. It is supported by an
                  initial review of dataflow programming in the 1970s and 1980s
                  that led to current topics of research. It then discusses how
                  dataflow programming evolved toward a hybrid von Neumann
                  dataflow formulation, and adopted a more coarse-grained
                  approach. Recent trends toward dataflow visual programming
                  languages are then discussed with reference to key graphical
                  dataflow languages and their development environments.
                  Finally, the article details four key open topics in dataflow
                  programming languages.},
  journal         = {ACM Comput. Surv.},
  month           = mar,
  pages           = {1–34},
  numpages        = 34,
  keywords        = {co-ordination languages, Dataflow, software engineering,
                  graphical programming, multithreading, component software,
                  data flow visual programming}
}

@inproceedings{10.1145/1017472.1017488,
  author          = {Kiselyov, Oleg and L\"{a}mmel, Ralf and Schupke, Keean},
  title           = {Strongly Typed Heterogeneous Collections},
  year            = 2004,
  isbn            = 1581138504,
  publisher       = {Association for Computing Machinery},
  address         = {New York, NY, USA},
  url             = {https://doi.org/10.1145/1017472.1017488},
  doi             = {10.1145/1017472.1017488},
  abstract        = {A heterogeneous collection is a datatype that is capable of
                  storing data of different types, while providing operations
                  for look-up, update, iteration, and others. There are various
                  kinds of heterogeneous collections, differing in
                  representation, invariants, and access operations. We describe
                  HLIST - a Haskell library for strongly typed heterogeneous
                  collections including extensible records. We illustrate
                  HLIST's benefits in the context of type-safe database access
                  in Haskell. The HLIST library relies on common extensions of
                  Haskell 98. Our exploration raises interesting issues
                  regarding Haskell's type system, in particular, avoidance of
                  overlapping instances, and reification of type equality and
                  type unification.},
  booktitle       = {Proceedings of the 2004 ACM SIGPLAN Workshop on Haskell},
  pages           = {96–107},
  numpages        = 12,
  keywords        = {haskell, type-indexed rows, collections, extensible
                  records, type improvement, type equality, type-safe database
                  access, dependently typed programming},
  location        = {Snowbird, Utah, USA},
  series          = {Haskell '04}
}

@article{10.1145/1160074.1159811,
  author          = {Peyton Jones, Simon and Vytiniotis, Dimitrios and Weirich,
                  Stephanie and Washburn, Geoffrey},
  title           = {Simple Unification-Based Type Inference for GADTs},
  year            = 2006,
  issue_date      = {September 2006},
  publisher       = {Association for Computing Machinery},
  address         = {New York, NY, USA},
  volume          = 41,
  number          = 9,
  issn            = {0362-1340},
  url             = {https://doi.org/10.1145/1160074.1159811},
  doi             = {10.1145/1160074.1159811},
  abstract        = {Generalized algebraic data types (GADTs), sometimes known
                  as "guarded recursive data types" or "first-class phantom
                  types", are a simple but powerful generalization of the data
                  types of Haskell and ML. Recent works have given compelling
                  examples of the utility of GADTs, although type inference is
                  known to be difficult. Our contribution is to show how to
                  exploit programmer-supplied type annotations to make the type
                  inference task almost embarrassingly easy. Our main technical
                  innovation is wobbly types, which express in a declarative way
                  the uncertainty caused by the incremental nature of typical
                  type-inference algorithms.},
  journal         = {SIGPLAN Not.},
  month           = sep,
  pages           = {50–61},
  numpages        = 12,
  keywords        = {type inference, generalized algebraic data types}
}

@inproceedings{10.1145/1328438.1328475,
  author          = {Johann, Patricia and Ghani, Neil},
  title           = {Foundations for Structured Programming with GADTs},
  year            = 2008,
  isbn            = 9781595936899,
  publisher       = {Association for Computing Machinery},
  address         = {New York, NY, USA},
  url             = {https://doi.org/10.1145/1328438.1328475},
  doi             = {10.1145/1328438.1328475},
  abstract        = {GADTs are at the cutting edge of functional programming and
                  becomemore widely used every day. Nevertheless, the semantic
                  foundations underlying GADTs are not well understood. In this
                  paper we solve this problem by showing that the standard
                  theory of data types as carriers of initial algebras of
                  functors can be extended from algebraic and nested data types
                  to GADTs. We then use this observation to derivean initial
                  algebra semantics for GADTs, thus ensuring that all of the
                  accumulated knowledge about initial algebras can be brought to
                  bear on them. Next, we use our initial algebra semantics for
                  GADTs to derive expressive and principled tools --- analogous
                  to the well-known and widely-used ones for algebraic and
                  nested data types---for reasoning about, programming with, and
                  improving the performance of programs involving, GADTs; we
                  christen such a collection of tools for a GADT an initial
                  algebra package. Along the way, we give a constructive
                  demonstration that every GADT can be reduced to one which uses
                  only the equality GADT and existential quantification.
                  Although other such reductions exist in the literature, ours
                  is entirely local, is independent of any particular syntactic
                  presentation of GADTs, and can be implemented in the host
                  language, rather than existing solely as a metatheoretical
                  artifact. The main technical ideas underlying our approach are
                  (i) to modify the notion of a higher-order functor so that
                  GADTs can be seen as carriers of initial algebras of
                  higher-order functors, and (ii) to use left Kan extensions to
                  trade arbitrary GADTs for simpler-but-equivalent ones for
                  which initial algebra semantics can bederived.},
  booktitle       = {Proceedings of the 35th Annual ACM SIGPLAN-SIGACT Symposium
                  on Principles of Programming Languages},
  pages           = {297–308},
  numpages        = 12,
  keywords        = {initial algebra semantics, program fusion, GADTs},
  location        = {San Francisco, California, USA},
  series          = {POPL '08}
}

@inproceedings{10.1145/1411204.1411215,
  author          = {Schrijvers, Tom and Peyton Jones, Simon and Chakravarty,
                  Manuel and Sulzmann, Martin},
  title           = {Type Checking with Open Type Functions},
  year            = 2008,
  isbn            = 9781595939197,
  publisher       = {Association for Computing Machinery},
  address         = {New York, NY, USA},
  url             = {https://doi.org/10.1145/1411204.1411215},
  doi             = {10.1145/1411204.1411215},
  abstract        = {We report on an extension of Haskell with open type-level
                  functions and equality constraints that unifies earlier work
                  on GADTs, functional dependencies, and associated types. The
                  contribution of the paper is that we identify and characterise
                  the key technical challenge of entailment checking; and we
                  give a novel, decidable, sound, and complete algorithm to
                  solve it, together with some practically-important variants.
                  Our system is implemented in GHC, and is already in active
                  use.},
  booktitle       = {Proceedings of the 13th ACM SIGPLAN International
                  Conference on Functional Programming},
  pages           = {51–62},
  numpages        = 12,
  keywords        = {type families, type functions, type checking, Haskell},
  location        = {Victoria, BC, Canada},
  series          = {ICFP '08}
}

@inproceedings{10.1145/2036918.2036930,
  author          = {Bahr, Patrick and Hvitved, Tom},
  title           = {Compositional Data Types},
  year            = 2011,
  isbn            = 9781450308618,
  publisher       = {Association for Computing Machinery},
  address         = {New York, NY, USA},
  url             = {https://doi.org/10.1145/2036918.2036930},
  doi             = {10.1145/2036918.2036930},
  abstract        = {Building on Wouter Swierstra's Data types \`{a} la carte,
                  we present a comprehensive Haskell library of compositional
                  data types suitable for practical applications. In this
                  framework, data types and functions on them can be defined in
                  a modular fashion. We extend the existing work by implementing
                  a wide array of recursion schemes including monadic
                  computations. Above all, we generalise recursive data types to
                  contexts, which allow us to characterise a special yet
                  frequent kind of catamorphisms. The thus established notion of
                  term homomorphisms allows for flexible reuse and enables
                  short-cut fusion style deforestation which yields considerable
                  speedups. We demonstrate our framework in the setting of
                  compiler construction, and moreover, we compare compositional
                  data types with generic programming techniques and show that
                  both are comparable in run-time performance and expressivity
                  while our approach allows for stricter types. We substantiate
                  this conclusion by lifting compositional data types to
                  recursive data types and generalised algebraic data types.
                  Lastly, we compare the run-time performance of our techniques
                  with traditional implementations over algebraic data types.
                  The results are surprisingly good.},
  booktitle       = {Proceedings of the Seventh ACM SIGPLAN Workshop on Generic
                  Programming},
  pages           = {83–94},
  numpages        = 12,
  keywords        = {mutual recursion, deforestation, reusability, algebraic
                  programming},
  location        = {Tokyo, Japan},
  series          = {WGP '11}
}

@inproceedings{10.1145/2103786.2103795,
  author          = {Yorgey, Brent A. and Weirich, Stephanie and Cretin, Julien
                  and Peyton Jones, Simon and Vytiniotis, Dimitrios and
                  Magalh\~{a}es, Jos\'{e} Pedro},
  title           = {Giving Haskell a Promotion},
  year            = 2012,
  isbn            = 9781450311205,
  publisher       = {Association for Computing Machinery},
  address         = {New York, NY, USA},
  url             = {https://doi.org/10.1145/2103786.2103795},
  doi             = {10.1145/2103786.2103795},
  abstract        = {Static type systems strive to be richly expressive while
                  still being simple enough for programmers to use. We describe
                  an experiment that enriches Haskell's kind system with two
                  features promoted from its type system: data types and
                  polymorphism. The new system has a very good power-to-weight
                  ratio: it offers a significant improvement in expressiveness,
                  but, by re-using concepts that programmers are already
                  familiar with, the system is easy to understand and
                  implement.},
  booktitle       = {Proceedings of the 8th ACM SIGPLAN Workshop on Types in
                  Language Design and Implementation},
  pages           = {53–66},
  numpages        = 14,
  keywords        = {promotion, haskell, polymorphism, kinds},
  location        = {Philadelphia, Pennsylvania, USA},
  series          = {TLDI '12}
}

@inproceedings{10.1145/2364506.2364522,
  author          = {Eisenberg, Richard A. and Weirich, Stephanie},
  title           = {Dependently Typed Programming with Singletons},
  year            = 2012,
  isbn            = 9781450315746,
  publisher       = {Association for Computing Machinery},
  address         = {New York, NY, USA},
  url             = {https://doi.org/10.1145/2364506.2364522},
  doi             = {10.1145/2364506.2364522},
  abstract        = {Haskell programmers have been experimenting with dependent
                  types for at least a decade, using clever encodings that push
                  the limits of the Haskell type system. However, the cleverness
                  of these encodings is also their main drawback. Although the
                  ideas are inspired by dependently typed programs, the code
                  looks significantly different. As a result, GHC implementors
                  have responded with extensions to Haskell's type system, such
                  as GADTs, type families, and datatype promotion. However,
                  there remains a significant difference between programming in
                  Haskell and in full-spectrum dependently typed languages.
                  Haskell enforces a phase separation between runtime values and
                  compile-time types. Therefore, singleton types are necessary
                  to express the dependency between values and types. These
                  singleton types introduce overhead and redundancy for the
                  programmer.This paper presents the singletons library, which
                  generates the boilerplate code necessary for dependently typed
                  programming using GHC. To compare with full-spectrum
                  languages, we present an extended example based on an Agda
                  interface for safe database access. The paper concludes with a
                  detailed discussion on the current capabilities of GHC for
                  dependently typed programming and suggestions for future
                  extensions to better support this style of programming.},
  booktitle       = {Proceedings of the 2012 Haskell Symposium},
  pages           = {117–130},
  numpages        = 14,
  keywords        = {haskell, dependently typed programming, singletons, gadts},
  location        = {Copenhagen, Denmark},
  series          = {Haskell '12}
}

@inproceedings{10.1145/2535838.2535856,
  author          = {Eisenberg, Richard A. and Vytiniotis, Dimitrios and Peyton
                  Jones, Simon and Weirich, Stephanie},
  title           = {Closed Type Families with Overlapping Equations},
  year            = 2014,
  isbn            = 9781450325448,
  publisher       = {Association for Computing Machinery},
  address         = {New York, NY, USA},
  url             = {https://doi.org/10.1145/2535838.2535856},
  doi             = {10.1145/2535838.2535856},
  abstract        = {Open, type-level functions are a recent innovation in
                  Haskell that move Haskell towards the expressiveness of
                  dependent types, while retaining the look and feel of a
                  practical programming language. This paper shows how to
                  increase expressiveness still further, by adding closed type
                  functions whose equations may overlap, and may have non-linear
                  patterns over an open type universe. Although practically
                  useful and simple to implement, these features go beyond
                  conventional dependent type theory in some respects, and have
                  a subtle metatheory.},
  booktitle       = {Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on
                  Principles of Programming Languages},
  pages           = {671–683},
  numpages        = 13,
  keywords        = {type families, system fc, type-level computation, haskell},
  location        = {San Diego, California, USA},
  series          = {POPL '14}
}

@inproceedings{10.1145/3331545.3342598,
  author          = {Ekblad, Anton},
  title           = {Scoping Monadic Relational Database Queries},
  year            = 2019,
  isbn            = 9781450368131,
  publisher       = {Association for Computing Machinery},
  address         = {New York, NY, USA},
  url             = {https://doi.org/10.1145/3331545.3342598},
  doi             = {10.1145/3331545.3342598},
  abstract        = {We present a novel method for ensuring that relational
                  database queries in monadic embedded languages are
                  well-scoped, even in the presence of arbitrarily nested joins
                  and aggregates. Demonstrating our method, we present a
                  simplified version of Selda, a monadic relational database
                  query language embedded in Haskell, with full support for
                  nested inner queries. To our knowledge, Selda is the first
                  relational database query language to support fully general
                  inner queries using a monadic interface. In the Haskell
                  community, monads are the de facto standard interface to a
                  wide range of libraries and EDSLs. They are well understood by
                  researchers and practitioners alike, and they enjoy first
                  class support by the standard libraries. Due to the difficulty
                  of ensuring that inner queries are well-scoped, database
                  interfaces in Haskell have previously either been forced to
                  forego the benefits of monadic interfaces, or have had to do
                  without the generality afforded by inner queries.},
  booktitle       = {Proceedings of the 12th ACM SIGPLAN International Symposium
                  on Haskell},
  pages           = {114–124},
  numpages        = 11,
  keywords        = {haskell, relational databases, domain-specific languages,
                  scoping},
  location        = {Berlin, Germany},
  series          = {Haskell 2019}
}

@inproceedings{10.1145/3406088.3409023,
  author          = {Par\`{e}s, Yves and Bernardy, Jean-Philippe and Eisenberg,
                  Richard A.},
  title           = {Composing Effects into Tasks and Workflows},
  year            = 2020,
  isbn            = 9781450380508,
  publisher       = {Association for Computing Machinery},
  address         = {New York, NY, USA},
  url             = {https://doi.org/10.1145/3406088.3409023},
  doi             = {10.1145/3406088.3409023},
  abstract        = {Data science applications tend to be built by composing
                  tasks: discrete manipulations of data. These tasks are
                  arranged in directed acyclic graphs, and many frameworks exist
                  within the data science community supporting such a structure,
                  which is called a workflow. In realistic applications, we want
                  to be able to both analyze a workflow in the absence of data,
                  and to execute the workflow with data. This paper combines
                  effect handlers with arrow-like structures to abstract out
                  data science tasks. This combination of techniques enables a
                  modular design of workflows. Additionally, these workflows can
                  both be analyzed prior to running (e.g., to provide early
                  failure) and run conveniently. Our work is directly motivated
                  by real-world scenarios, and we believe that our approach is
                  applicable to new data science and machine learning
                  applications and frameworks.},
  booktitle       = {Proceedings of the 13th ACM SIGPLAN International Symposium
                  on Haskell},
  pages           = {80–94},
  numpages        = 15,
  keywords        = {Haskell, arrows, effect handlers},
  location        = {Virtual Event, USA},
  series          = {Haskell 2020}
}

@article{10.1145/44501.45065,
  author          = {Mitchell, John C. and Plotkin, Gordon D.},
  title           = {Abstract Types Have Existential Type},
  year            = 1988,
  issue_date      = {July 1988},
  publisher       = {Association for Computing Machinery},
  address         = {New York, NY, USA},
  volume          = 10,
  number          = 3,
  issn            = {0164-0925},
  url             = {https://doi.org/10.1145/44501.45065},
  doi             = {10.1145/44501.45065},
  abstract        = {Abstract data type declarations appear in typed programming
                  languages like Ada, Alphard, CLU and ML. This form of
                  declaration binds a list of identifiers to a type with
                  associated operations, a composite “value” we call a data
                  algebra. We use a second-order typed lambda calculus SOL to
                  show how data algebras may be given types, passed as
                  parameters, and returned as results of function calls. In the
                  process, we discuss the semantics of abstract data type
                  declarations and review a connection between typed programming
                  languages and constructive logic.},
  journal         = {ACM Trans. Program. Lang. Syst.},
  month           = jul,
  pages           = {470–502},
  numpages        = 33
}

@article{381846,
  author          = {E. A. {Lee} and T. M. {Parks}},
  journal         = {Proceedings of the IEEE},
  title           = {Dataflow process networks},
  year            = 1995,
  volume          = 83,
  number          = 5,
  pages           = {773-801},
  doi             = {10.1109/5.381846}
}

@article{4785860,
  author          = {G. E. {Moore}},
  journal         = {IEEE Solid-State Circuits Society Newsletter},
  title           = {Cramming more components onto integrated circuits,
                  Reprinted from Electronics, volume 38, number 8, April 19,
                  1965, pp.114 ff.},
  year            = 2006,
  volume          = 11,
  number          = 3,
  pages           = {33-35},
  doi             = {10.1109/N-SSC.2006.4785860}
}

@article{Coecke_2016,
  title           = {A mathematical theory of resources},
  volume          = 250,
  ISSN            = {0890-5401},
  url             = {http://dx.doi.org/10.1016/j.ic.2016.02.008},
  DOI             = {10.1016/j.ic.2016.02.008},
  journal         = {Information and Computation},
  publisher       = {Elsevier BV},
  author          = {Coecke, Bob and Fritz, Tobias and Spekkens, Robert W.},
  year            = 2016,
  month           = {Oct},
  pages           = {59–86}
}

@inproceedings{DBLP:conf/ifip/Kahn74,
  author          = {Gilles Kahn},
  editor          = {Jack L. Rosenfeld},
  title           = {The Semantics of a Simple Language for Parallel
                  Programming},
  booktitle       = {Information Processing, Proceedings of the 6th {IFIP}
                  Congress 1974, Stockholm, Sweden, August 5-10, 1974},
  pages           = {471--475},
  publisher       = {North-Holland},
  year            = 1974,
  timestamp       = {Fri, 17 Jan 2020 19:17:14 +0100},
  biburl          = {https://dblp.org/rec/conf/ifip/Kahn74.bib},
  bibsource       = {dblp computer science bibliography, https://dblp.org}
}

@article{SVENNINGSSON2015143,
  title           = {Combining deep and shallow embedding of domain-specific
                  languages},
  journal         = {Computer Languages, Systems \& Structures},
  volume          = 44,
  pages           = {143-165},
  year            = 2015,
  note            = {SI: TFP 2011/12},
  issn            = {1477-8424},
  doi             = {https://doi.org/10.1016/j.cl.2015.07.003},
  url             =
                  {https://www.sciencedirect.com/science/article/pii/S1477842415000500},
  author          = {Josef Svenningsson and Emil Axelsson},
  keywords        = {Domain specific languages, Shallow embedding, Deep
                  embedding, Fusion, Monads},
  abstract        = {We present a technique to combine deep and shallow
                  embedding in the context of compiling embedded languages in
                  order to provide the benefits of both techniques. When
                  compiling embedded languages it is natural to use an abstract
                  syntax tree to represent programs. This is known as a deep
                  embedding and it is a rather cumbersome technique compared to
                  other forms of embedding, typically leading to more code and
                  being harder to extend. In shallow embeddings, language
                  constructs are mapped directly to their semantics which yields
                  more flexible and succinct implementations. But shallow
                  embeddings are not well-suited for compiling embedded
                  languages. Our technique uses a combination of deep and
                  shallow embedding, which helps keeping the deep embedding
                  small and makes extending the embedded language much easier.
                  The technique also has some unexpected but welcome secondary
                  effects. It provides fusion of functions to remove
                  intermediate results for free without any additional effort.
                  It also helps us to give the embedded language a more natural
                  programming interface.}
}

@misc{airflow,
  title           = {Airflow: https://airflow.apache.org},
  url             = {http://airflow.apache.org},
  author          = {Apache}
}

@misc{bentley_2020,
  title           = {The end of Moore's Law: what happens next?},
  url             =
                  {https://www.sciencefocus.com/future-technology/when-the-chips-are-down/},
  journal         = {BBC Science Focus Magazine},
  author          = {Bentley, Dr Peter},
  year            = 2020,
  month           = {Apr}
}

@book{costello_2012,
  title           = {Figure 15. Connecting a Math patch to the Sprite Width and
                  Height inlets},
  url             =
                  {http://www.csounds.com/journal/issue17/costello_quartz_composer_csound.html},
  series          = {Creating Graphical User Interfaces for Csound using Quartz
                  Composer},
  publisher       = {Csound Journal},
  author          = {Costello, Edward},
  year            = 2012,
  month           = {Nov}
}

@misc{hermans2011breviz,
  title           = {Breviz: Visualizing Spreadsheets using Dataflow Diagrams},
  author          = {Felienne Hermans and Martin Pinzger and Arie van Deursen},
  year            = 2011,
  eprint          = {1111.6895},
  archivePrefix   = {arXiv},
  primaryClass    = {cs.SE}
}

@misc{hu_2015,
  title           = {Building Out the SeatGeek Data Pipeline},
  url             =
                  {https://chairnerd.seatgeek.com/building-out-the-seatgeek-data-pipeline/},
  journal         = {ChairNerd},
  author          = {Hu, Tiffany},
  year            = 2015,
  month           = {Jan}
}

@misc{karki_2020,
  title           = {Can you guess how much data is generated every day?},
  url             =
                  {https://www.takeo.ai/can-you-guess-how-much-data-is-generated-every-day/},
  journal         = {Takeo},
  author          = {Karki, Dhruba},
  year            = 2020,
  month           = {Nov}
}

@book{lane1998categories,
  title           = {Categories for the Working Mathematician},
  author          = {Lane, S.M. and Axler, S.J. and Springer-Verlag (Nowy Jork).
                  and Gehring, F.W. and Halmos, P.R.},
  isbn            = 9780387984032,
  lccn            = 97045229,
  series          = {Graduate Texts in Mathematics},
  url             = {https://books.google.co.uk/books?id=MXboNPdTv7QC},
  year            = 1998,
  publisher       = {Springer}
}

@article{mcbride2011functional,
  title           = {Functional pearl: Kleisli arrows of outrageous fortune},
  author          = {McBride, Conor},
  journal         = {Journal of Functional Programming (accepted for
                  publication)},
  year            = 2011
}

@article{monadic_cata,
  title           = "Monadic Maps and Folds for Arbitrary Datatypes",
  abstract        = "Each datatype constructor comes equiped not only with a
                  so-called map and fold (catamorphism), as is widely known,
                  but, under some condition, also with a kind of map and fold
                  that are related to an arbitrary given monad. This result
                  follows from the preservation of initiality under lifting from
                  the category of algebras in a given category to a certain
                  other category of algebras in the Kleisli category related to
                  the monad.",
  keywords        = "METIS-121742, EWI-8197, IR-66622",
  author          = "M.M. Fokkinga",
  note            = "Imported from EWI/DB PMS [db-utwente:tech:0000003538]",
  year            = 1994,
  month           = jun,
  language        = "Undefined",
  pages           = "--",
  journal         = "Memoranda informatica",
  issn            = "0924-3755",
  publisher       = "University of Twente",
  number          = "94-28",
}

@article{parsley,
  author          = {Willis, Jamie and Wu, Nicolas and Pickering, Matthew},
  title           = {Staged Selective Parser Combinators},
  year            = 2020,
  issue_date      = {August 2020},
  publisher       = {Association for Computing Machinery},
  address         = {New York, NY, USA},
  volume          = 4,
  number          = {ICFP},
  url             = {https://doi.org/10.1145/3409002},
  doi             = {10.1145/3409002},
  abstract        = {Parser combinators are a middle ground between the fine
                  control of hand-rolled parsers and the high-level almost
                  grammar-like appearance of parsers created via parser
                  generators. They also promote a cleaner, compositional design
                  for parsers. Historically, however, they cannot match the
                  performance of their counterparts. This paper describes how to
                  compile parser combinators into parsers of hand-written
                  quality. This is done by leveraging the static information
                  present in the grammar by representing it as a tree. However,
                  in order to exploit this information, it will be necessary to
                  drop support for monadic computation since this generates
                  dynamic structure. Selective functors can help recover lost
                  functionality in the absence of monads, and the parser tree
                  can be partially evaluated with staging. This is implemented
                  in a library called Parsley.},
  journal         = {Proc. ACM Program. Lang.},
  month           = aug,
  articleno       = 120,
  numpages        = 30,
  keywords        = {parsers, meta-programming, combinators}
}

@article{phantom_types,
  author          = {Cheney, James and Hinze, Ralf},
  year            = 2003,
  month           = 01,
  title           = {First-Class Phantom Types}
}

@misc{pipes,
  title           = {pipes: https://hackage.haskell.org/package/pipes},
  url             = {https://hackage.haskell.org/package/pipes},
  journal         = {Hackage},
  author          = {Gonzalez, Gabriel}
}

@misc{quartz,
  title           = {Quartz Composer User Guide},
  url             =
                  {https://developer.apple.com/library/archive/documentation/GraphicsImaging/Conceptual/QuartzComposerUserGuide/qc_intro/qc_intro.html#//apple_ref/doc/uid/TP40005381},
  journal         = {Introduction to Quartz Composer User Guide},
  publisher       = {Apple Inc},
  year            = 2007,
  month           = {Jul}
}

@InProceedings{scans,
  author          = "Hinze, Ralf",
  editor          = "Kozen, Dexter",
  title           = "An Algebra of Scans",
  booktitle       = "Mathematics of Program Construction",
  year            = 2004,
  publisher       = "Springer Berlin Heidelberg",
  address         = "Berlin, Heidelberg",
  pages           = "186--210",
  abstract        = "A parallel prefix circuit takes n inputs x1, x2, ..., xnand
                  produces the n outputs x1, x1 ∘ x2, ...,
                  x1{\thinspace}∘{\thinspace}x2{\thinspace}∘{\thinspace}⋯{\thinspace}∘{\thinspace}xn,
                  where'∘' is an arbitrary associative binary operation.
                  Parallel prefix circuits and their counterparts in software,
                  parallel prefix computations or scans, have numerous
                  applications ranging from fast integer addition over parallel
                  sorting to convex hull problems. A parallel prefix circuit can
                  be implemented in a variety of ways taking into account
                  constraints on size, depth, or fan-out. Traditionally,
                  implementations are either defined graphically or by
                  enumerating the underlying graph. Both approaches have their
                  pros and cons. A figure if well drawn conveys the possibly
                  recursive structure of the scan but it is not amenable to
                  formal manipulation. A description in form of a graph while
                  rigorous obscures the structure of a scan and is equally hard
                  to manipulate. In this paper we show that parallel prefix
                  circuits enjoy a very pleasant algebra. Using only two basic
                  building blocks and four combinators all standard designs can
                  be described succinctly and rigorously. The rules of the
                  algebra allow us to prove the circuits correct and to derive
                  circuit designs in a systematic manner.",
  isbn            = "978-3-540-27764-4"
}

@misc{spotify_luigi,
  title           = {Luigi: https://github.com/spotify/luigi},
  url             = {https://github.com/spotify/luigi},
  journal         = {GitHub},
  author          = {Spotify}
}

@misc{spotify_luigi_docs_2020,
  title           = {Tasks},
  url             = {https://luigi.readthedocs.io/en/stable/tasks.html},
  journal         = {Tasks - Luigi 2.8.13 documentation},
  author          = {Spotify},
  year            = 2020,
  month           = {Apr}
}

@article{swierstra_2008,
  title           = {Data types à la carte},
  volume          = 18,
  DOI             = {10.1017/S0956796808006758},
  number          = 4,
  journal         = {Journal of Functional Programming},
  publisher       = {Cambridge University Press},
  author          = {SWIERSTRA, WOUTER},
  year            = 2008,
  pages           = {423–436}
}

@misc{tableauPrep,
  title           = {Tableau Prep Builder \& Prep Conductor: A self-service data
                  preparation solution},
  url             = {https://www.tableau.com/en-gb/products/prep},
  journal         = {GitHub},
  author          = {Tableau},
  year            = 2021
}

@misc{wadler_1998,
  url             =
                  {https://homepages.inf.ed.ac.uk/wadler/papers/expression/expression.txt},
  title           = {The Expression Problem},
  author          = {Wadler, Phillip},
  year            = 1998,
  month           = {Nov}
}

@misc{wuYoda,
  title           = {Yoda: A simple combinator library},
  url             = {https://github.com/zenzike/yoda},
  journal         = {GitHub},
  author          = {Wu, Nicolas},
  year            = 2018
}
